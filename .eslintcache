[{"/Users/victoriaacuna/Desktop/TensorflowJS/emotions/src/index.js":"1","/Users/victoriaacuna/Desktop/TensorflowJS/emotions/src/App.js":"2","/Users/victoriaacuna/Desktop/TensorflowJS/emotions/src/reportWebVitals.js":"3","/Users/victoriaacuna/Desktop/TensorflowJS/emotions/src/Routes.js":"4","/Users/victoriaacuna/Desktop/TensorflowJS/emotions/src/components/blazeface.js":"5"},{"size":554,"mtime":1612118782876,"results":"6","hashOfConfig":"7"},{"size":4509,"mtime":1611538571338,"results":"8","hashOfConfig":"7"},{"size":362,"mtime":1610828665501,"results":"9","hashOfConfig":"7"},{"size":650,"mtime":1612119653924,"results":"10","hashOfConfig":"7"},{"size":6884,"mtime":1612150191214,"results":"11","hashOfConfig":"7"},{"filePath":"12","messages":"13","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"14","usedDeprecatedRules":"15"},"852onr",{"filePath":"16","messages":"17","errorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":"18","usedDeprecatedRules":"15"},{"filePath":"19","messages":"20","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"15"},{"filePath":"21","messages":"22","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"23","usedDeprecatedRules":"15"},{"filePath":"24","messages":"25","errorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},"/Users/victoriaacuna/Desktop/TensorflowJS/emotions/src/index.js",["26"],"import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\nimport Routes from './Routes';\n\nReactDOM.render(\n  <React.StrictMode>\n    {/* <App /> */}\n    <Routes />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n",["27","28"],"/Users/victoriaacuna/Desktop/TensorflowJS/emotions/src/App.js",["29","30","31"],"import React, {useState, useRef, useEffect} from 'react';\nimport * as cocoSsd from \"@tensorflow-models/coco-ssd\";\nimport \"@tensorflow/tfjs\";\nimport logo from './logo.svg';\nimport './App.css';\n\nfunction App() {\n\n  const [sectionClass, setSectionClass] = useState(\"invisible\")\n  let video = document.getElementById('webcam');\n  const liveView = document.getElementById('liveView');\n  // const demosSection = document.getElementById('demos');\n  // const enableWebcamButton = document.getElementById('webcamButton');\n  \n  // Check if webcam access is supported.\n  const getUserMediaSupported= ()=> {\n      return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);\n  }\n    \n  // If webcam supported, add event listener to button for when user\n  // wants to activate it to call enableCam function which we will \n  // define in the next step.\n\n    \n  // Enable the live webcam view and start classification.\n  const enableCam = (event) => {\n\n      // Only continue if the COCO-SSD has finished loading.\n      if (!model) {\n        return;\n      }\n      \n      // Hide the button once clicked.\n      event.target.classList.add('removed');  \n      \n      // getUsermedia parameters to force video but not audio.\n      const constraints = {\n        video: true\n      };\n    \n      // Activate the webcam stream.\n      navigator.mediaDevices.getUserMedia(constraints)\n      .then( (stream) => {\n        video.srcObject = stream;\n        video.addEventListener('loadeddata', predictWebcam);\n      });\n  }\n\n  // Pretend model has loaded so we can try out the webcam code.\n  // Store the resulting model in the global scope of our app.\n  let model = undefined;\n  \n  // Before we can use COCO-SSD class we must wait for it to finish\n  // loading. Machine Learning models can be large and take a moment \n  // to get everything needed to run.\n  // Note: cocoSsd is an external object loaded from our index.html\n  // script tag import so ignore any warning in Glitch.\n  cocoSsd.load()\n  .then( (loadedModel) => {\n    model = loadedModel;\n    // Show demo section now model is ready to use.\n    setSectionClass(\"\")\n  });\n  \n  let children = [];\n  \n  const predictWebcam = () => {\n\n    // Now let's start classifying a frame in the stream.\n    model.detect(video)\n    .then( (predictions) => {\n\n      // Remove any highlighting we did previous frame.\n      for (let i = 0; i < children.length; i++) {\n        liveView.removeChild(children[i]);\n      }\n      children.splice(0);\n      \n      // Now lets loop through predictions and draw them to the live view if\n      // they have a high confidence score.\n      for (let n = 0; n < predictions.length; n++) {\n\n        // If we are over 66% sure we are sure we classified it right, draw it!\n        if (predictions[n].score > 0.66) {\n          \n          const p = document.createElement('p');\n          p.innerText = predictions[n].class  + ' - with ' \n              + Math.round(parseFloat(predictions[n].score) * 100) \n              + '% confidence.';\n          p.style = 'margin-left: ' + predictions[n].bbox[0] + 'px; margin-top: '\n              + (predictions[n].bbox[1] - 10) + 'px; width: ' \n              + (predictions[n].bbox[2] - 10) + 'px; top: 0; left: 0;';\n  \n          const highlighter = document.createElement('div');\n          highlighter.setAttribute('class', 'highlighter');\n          highlighter.style = 'left: ' + predictions[n].bbox[0] + 'px; top: '\n              + predictions[n].bbox[1] + 'px; width: ' \n              + predictions[n].bbox[2] + 'px; height: '\n              + predictions[n].bbox[3] + 'px;';\n  \n          liveView.appendChild(highlighter);\n          liveView.appendChild(p);\n          children.push(highlighter);\n          children.push(p);\n        }\n      }\n      \n      // Call this function again to keep predicting when the browser is ready.\n      window.requestAnimationFrame(predictWebcam);\n\n    });\n  }\n  \n\n  const handleEnableCamera = (event) => {\n\n    if (getUserMediaSupported()) {\n      enableCam(event);\n    } else {\n      console.warn('getUserMedia() is not supported by your browser');\n    }\n\n  }\n  \n\n\n  return (\n    <div className=\"App\">\n\n      <h1>Emotions detection</h1>\n\n\n    \n    <section id=\"demos\" className={sectionClass}>\n\n   \n      \n      <div id=\"liveView\" className=\"camView\">\n        <button id=\"webcamButton\" onClick={handleEnableCamera}>Enable Webcam</button>\n        <video id=\"webcam\" autoPlay width=\"640\" height=\"480\"></video>\n      </div>\n    </section>\n</div>\n  );\n}\n\nexport default App;\n","/Users/victoriaacuna/Desktop/TensorflowJS/emotions/src/reportWebVitals.js",[],"/Users/victoriaacuna/Desktop/TensorflowJS/emotions/src/Routes.js",["32"],"import React, { useState } from 'react';\nimport {BrowserRouter, Switch, Route} from 'react-router-dom';\nimport App from './App';\nimport Blazeface from './components/blazeface';\n// import ProtectedRoute from './ProtectedRoute'\n\nfunction Routes() {\n\n  return (\n    <div className=\"Routes\">\n      <BrowserRouter>\n        <Switch>\n          {/* Users */}\n          <Route exact path=\"/\" component={App}/>,\n          <Route exact path=\"/blazeface\" component={Blazeface}/>,\n          {/* <ProtectedRoute exact path=\"/:landing/main\" role={isUser} component={UserMain}/>, */}\n        </Switch>\n      </BrowserRouter>\n    </div>\n  );\n}\n\nexport default Routes;","/Users/victoriaacuna/Desktop/TensorflowJS/emotions/src/components/blazeface.js",["33","34","35","36"],{"ruleId":"37","severity":1,"message":"38","line":4,"column":8,"nodeType":"39","messageId":"40","endLine":4,"endColumn":11},{"ruleId":"41","replacedBy":"42"},{"ruleId":"43","replacedBy":"44"},{"ruleId":"37","severity":1,"message":"45","line":1,"column":26,"nodeType":"39","messageId":"40","endLine":1,"endColumn":32},{"ruleId":"37","severity":1,"message":"46","line":1,"column":34,"nodeType":"39","messageId":"40","endLine":1,"endColumn":43},{"ruleId":"37","severity":1,"message":"47","line":4,"column":8,"nodeType":"39","messageId":"40","endLine":4,"endColumn":12},{"ruleId":"37","severity":1,"message":"48","line":1,"column":17,"nodeType":"39","messageId":"40","endLine":1,"endColumn":25},{"ruleId":"37","severity":1,"message":"49","line":2,"column":8,"nodeType":"39","messageId":"40","endLine":2,"endColumn":17},{"ruleId":"37","severity":1,"message":"50","line":4,"column":13,"nodeType":"39","messageId":"40","endLine":4,"endColumn":21},{"ruleId":"37","severity":1,"message":"51","line":13,"column":11,"nodeType":"39","messageId":"40","endLine":13,"endColumn":19},{"ruleId":"52","severity":1,"message":"53","line":180,"column":8,"nodeType":"54","endLine":180,"endColumn":10,"suggestions":"55"},"no-unused-vars","'App' is defined but never used.","Identifier","unusedVar","no-native-reassign",["56"],"no-negated-in-lhs",["57"],"'useRef' is defined but never used.","'useEffect' is defined but never used.","'logo' is defined but never used.","'useState' is defined but never used.","'PropTypes' is defined but never used.","'tfjsWasm' is defined but never used.","'liveView' is assigned a value but never used.","react-hooks/exhaustive-deps","React Hook useEffect has a missing dependency: 'setupPage'. Either include it or remove the dependency array.","ArrayExpression",["58"],"no-global-assign","no-unsafe-negation",{"desc":"59","fix":"60"},"Update the dependencies array to be: [setupPage]",{"range":"61","text":"62"},[5959,5961],"[setupPage]"]